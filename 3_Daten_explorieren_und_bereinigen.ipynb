{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten explorieren und bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Notebook lernst du\n",
    "+ wie man Daten in Python einliest und wie man anschließend mit diesen arbeiten kann.\n",
    "+ wie man die Daten für die Bereinigung vorbereitet.\n",
    "+ wie man gezielt nach fehlerhaften Daten sucht und wie man mit diesen umgehen kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einbinden von Bibliotheken\n",
    "\n",
    "Wir beginnen damit die **Bibliotheken**, die wir später benötigen werden, zu importieren. Eine Bibliothek (in Python) ist eine Sammlung von nützlichen Funktionen und Werkzeugen. In unserem Fall helfen sie uns bei beim Einlesen, Manipulieren und Visualisieren der Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken zur Speicherung und Manipulation der Daten in sogenannten DataFrames (Tabellen)\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Bibliotheken zur Visualisierung der Daten\n",
    "import cufflinks as cf\n",
    "from ipywidgets import interactive\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kennenlernen der Daten\n",
    "\n",
    "Wir haben bereits den pandas-Datentyp `DataFrame` kennengelernt und Daten aus einer Excel-Tabelle in ein solches DataFrame übertragen. Für das folgende Notebook stehen uns die Parkplatzdaten der Firma ASP aus dem Jahre 2017 zur Verfügung. Du findest Sie in dem Ordner `Daten` unter dem Namen `Einlaeufe2017.csv`.\n",
    "\n",
    "![Liboriberg](Ressourcen/parkplaetze.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Excel-Tabelle beginnt mit einem TimeStamp, in dem Tag, Monat, Jahr und die volle Stunden der Tageszeit kodiert sind. Für die verschiedenen Parkflächen folgt dann eine Belegungszahl, die Ein- und Ausfahrten der aktuellen Stunde und zwei Korrekturwerte, die nur ab und zu mit Werten belegt sind. Das Zählen der Ein- und Ausfahrten erfolgt über Induktionsschleifen an der Einfahrt/Ausfahrt des jeweiligen Parkplatzes. Die einzelnen Parkflächen können nicht separat erfasst werden.\n",
    "\n",
    "![Parkplatzdaten-Excel](Ressourcen/Parkplatzdaten-Excel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch einen Export dieser Tabelle in das CSV-Format erhalten wir eine Textdatei in deren ersten Zeile die Spaltennamen der Excel-Tabelle, durch Semikolon getrennt, abgelegt sind. In den folgenden Zeilen stehen dann die Daten, die jeweils durch den TimeStamp eingeleitet werden und dann je Spalte durch Semikolon getrennt werden.\n",
    "\n",
    "![Parkplatzdaten-CSV](Ressourcen/Parkplatzdaten-CSV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf der Internetseite von ASP finden wir eine Übersicht über die Zuordnung der Parkplätze und deren Kapazitäten\n",
    "\n",
    "| Parkplatz | Standort | Kapazität |\n",
    "| :--- | :--- | :--- |\n",
    "| P1 | Tiefgarage Königsplatz | 640 |\n",
    "| P2 | Parkplatz Florianstraße | 290 |\n",
    "| P3 | Parkhaus Neuhäuser Tor | 540 |\n",
    "| P41 & P42 | Parkplatz Paderhalle / Maspernplatz | 670 |\n",
    "| P5 | Parkpalette Rolandsweg | 540 |\n",
    "| P6 | Parkhaus Liborigalerie | 500 |\n",
    "| P7 | Parkplatz Le-Mans-Wall/Liboriberg | 290 |\n",
    "| P8 | Tiefgarage Volksbank / Theater | 160 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten\n",
    "\n",
    "Die uns vorliegende CSV-Datei kann jetzt mit dem bereits behandelten `pandas` Kommando `read_csv(...)` in ein `DataFrame` eingelesen werden.\n",
    "\n",
    "Neben dem Dateipfad müsssen wir auch noch das Trennzeichen (`sep` für *seperator*) angeben, mit dem die einzelnen Spalten voneinander getrennt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einlesen der Daten\n",
    "df = pd.read_csv(filepath_or_buffer='Daten/Einlaeufe2017.csv', sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überblick verschaffen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anzeige `display`\n",
    "\n",
    "Wir können uns den Inhalt des `DataFrames` mit Hilfe der Funktion `display(...)` anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ können wir auch nur den Namen verwenden (Kurzschreibweise). Intern wird dann automatisch die Funktion `display` aufgerufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Art der Anzeige ist in der Regel sehr lang.\n",
    "\n",
    "Mit der Methode `head()` des `DataFrames` können wir uns auf die **ersten fünf Zeilen** unserer Daten beschränken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datentypen\n",
    "\n",
    "Mit dem Property `dtypes` des `DataFrames` bekommen wir eine Übersicht über die Datentypen der einzelnen Tabellenspalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas weist jeder Spalte beim Einlesen automatisch einen Typ zu.\n",
    "\n",
    "Pandas unterscheidet dabei zwischen folgenden Datentypen:\n",
    "\n",
    "| Pandas dtype | Python type | Verwendung |\n",
    "| :--- | :--- | :--- |\n",
    "| object | str | Text |\n",
    "| int64 | int | Ganze Zahlen |\n",
    "| float64 | float | Fließkommazahlen |\n",
    "| bool | bool | Wahrheitswerte |\n",
    "| datetime64 | datetime64 (numpy) | Datum und Uhrzeit |\n",
    "| timedelta[ns] | NA | Abstände zwischen zwei Zeitpunkten |\n",
    "| category | NA | Endliche Liste von Kategorien |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe (Datentypen 1)\n",
    "\n",
    "Stellt mit Hilfe der Tabelle eine Vermutung auf, warum den Spalten unterschiedliche Datentypen zugewiesen wurden.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hier ist Platz für deine Antwort*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kennzahlen\n",
    "\n",
    "Die Methode `describe()` liefert einen Überblick über wichtige statistische Kennzahlen wie z.B. die Standardabweichung oder den Durchschnitt der Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "    \n",
    "### Aufgabe (Kennzahlen)\n",
    "\n",
    "Erklärt unter dem Aspekt der Datentypen, warum in der Übersicht, die wir mittels `describe()` erhalten haben, nicht alle Spalten auftauchen.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hier ist Platz für deine Antwort*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir kommen später noch auf das Problem mit den Datentypen zurück."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vorbereiten (Standardisierung)\n",
    "\n",
    "Bevor wir mit der eigentlichen Bereinigung den Daten (Schritt 10) beginnen, müssen wir die Daten dahingehend zunächst vorbereiten (Schritt 5-8). Das bedeutet, dass wir die Daten **formatieren** und **strukturieren**. Man spricht dabei auch von der **Standardisierung** der Daten.\n",
    "\n",
    "Beim Explorieren der ersten fünf Zeilen und mit einem Blick auf die Datentypen der einzelnen Spalten fallen gleich zwei größere Probleme ins Auge:\n",
    "\n",
    "1. Die Spalte `TimeStamp` enthält Angaben über **Datum und Uhrzeit** der Messung und sollte daher den Datentyp `timestamp` zugewiesen bekommen.\n",
    "2. Ganz rechts befinden sich unbenannte und offenbar **leere Spalten**. Diese sollen später in unserer Auswertung nicht auftauchen.\n",
    "\n",
    "Das erste Problem können wir lösen, indem wir manuell mit Hilfe der folgenden Anweisung die Spalte `TimeStamp` als Zeitstempel (`datetime`) interpretieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versuche die Spalte TimeStamp als DateTime zu interpretieren\n",
    "# dayfirst=True bewirkt, dass das Format DD-MM-YYYYY verwendet wird\n",
    "df['TimeStamp'] = pd.to_datetime(df['TimeStamp'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das zweite Problem lösen wir, indem wir alle Spalten löschen, die komplett leer sind (nur den Wert NA = *not assigned* enthalten)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lösche alle Spalten (axis=1), die leer sind\n",
    "df = df.dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe (Überprüfung)\n",
    "\n",
    "Überprüft, ob die Bereinigung erfolgreich war, indem ihr die Datentypen und das `DataFrame` anzeigen lasst.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für deine Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten indizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein **Index** (oder auch Schlüssel) identifiziert jede Zeile eines `DataFrames` eindeutig. Derzeit werden die Zeilen noch anhand der Zeilennummer (Position) identifiziert.\n",
    "\n",
    "Da unsere Daten einem zeitlichen Ablauf (TimeSeries) folgen liegt es nahe, die Spalte `TimeStamp` als Index zu wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wähle die Spalte TimeStamp als neuen Index\n",
    "df = df.set_index('TimeStamp')\n",
    "\n",
    "# Daten anhand des Zeitstempels chronologisch sortieren\n",
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun auf die Daten zu einem bestimmten Zeitpunkt durch Angabe des entsprechenden `TimeStamp` zugreifen:\n",
    "```python\n",
    "df['01-01-2017 01:00']\n",
    "```\n",
    "\n",
    "Wir werden später sehen, dass uns die Wahl des Index die graphische Darstellung erleichtert, da die Spalte TimeStamp nun automatisch auf der x-Achse dargestellt wird.\n",
    "\n",
    "Wenn wir uns das DataFrame nun erneut anschauen, sehen wir, dass die Spalte `TimeStamp` nun eingerückt ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desweiteren taucht sie nun nicht mehr in der Liste der Spaltennamen auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe (Slicing)\n",
    "\n",
    "Gib mit Hilfe des Index alle Daten zwischen dem 01.04.2017 und dem 03.05.2017 aus. Nutze hierfür den [`:`-Operator](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für deine Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten auf die Parkplatzbelegungen beschränken\n",
    "\n",
    "Da aus technischen Gründen die stündlichen Belegungszahlen der Parkplätze in der Regel nicht zu den Ein- und Ausfahrten des zugehörigen Parkplatzes passen, werden wir in den folgenden Auswertungen diese zusätzlichen Informationen ignorieren und alleine mit den Belegungszahlen der 8 Parkplätze weiterarbeiten.\n",
    "\n",
    "Dazu wählen wir alle Spalten aus, die den Ausdruck `AK` enthalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Auswahl aller Spalten, deren Namen die Zeichenkette AK beinhalten\n",
    "df_AK = df.filter(like = 'AK')\n",
    "# Ausgabe zur Kontrolle\n",
    "df_AK.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Problem mit dem Datentyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Schritt 3 haben wir festgestellt, dass nicht allen Spalten automatisch der Datentype `float64` zugewiesen wurde. Das liegt daran, dass die entsprechenden Spalten **nicht-numerische Werte (NaN)** und Sonderzeichen  (z.B. `-`) beinhalten.\n",
    "\n",
    "Das ist beispielsweise dann problematisch, wenn wir auf den Daten mathematisch operieren möchten. Möchten wir beispielsweise die **relative Belegung** des Parkplatzes ermitteln, müssen wir den **absoluten Wert** durch die **maximale Kapazität** des Parkplatzes dividieren.\n",
    "\n",
    "In den Spalten, die derzeit den Datentyp `object` haben kommt es dabei zu einem so genannten **TypeError**, da die Division auf nicht-numerischen Werten nicht definiert ist.\n",
    "\n",
    "**Beachte:** Die Parkplätze können auch überbelegt sein. Das ist dann der Fall, wenn Fahrzeuge auf einen vollen Parkplatz einfahren und nach einem Parkplatz suchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Berechnet die prozentuale Belegung aus der absoluten Anzahl der Fahrzeuge\n",
    "def prozentuale_belegung(belegung):\n",
    "    return belegung / 670\n",
    "\n",
    "# Das Anwenden der Funktion auf die Spalte P1AK erzeugt einen Fehler\n",
    "# Diesen fangen wir vorsichtshalber ab und geben ihn aus\n",
    "try:\n",
    "    df_AK['P1AK'].apply(func=prozentuale_belegung)\n",
    "except Exception as e:\n",
    "    print(type(e))\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst möchten wir feststellen, welche **Zeilen** betroffen sind. Dazu listen wir alle Zeilen auf, in denen **nicht-numerische Werte** stehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zeigt alle Zeilen an, in denen mindestens ein nicht-numerischer Wert steht\n",
    "\n",
    "# Wir wenden die Funktion pd.to_numeric auf df_AK mit dem Parameter coerce an. Diese versucht alle Werte in numerische\n",
    "# Werte umzuwandeln. Die Werte, die nicht als numerische Werte interpretiert werden können (z.B. '-') werden zu Null ('coerce').\n",
    "# .notnull.all(1) liefert alle Zeilen (0 = Spalten, 1 = Zeilen), die KEINEN Nullwert haben. Der Operator '~' invertiert\n",
    "# nun die Auswahl und liefert dementsprechend alle Zeilen, in denen mindestens einmal Null auftaucht, also in denen\n",
    "# mindestens ein nicht numerischer Wert steht.\n",
    "\n",
    "df_AK[~df_AK.apply(pd.to_numeric, errors='coerce').notnull().all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem wir die entsprechenden Zeilen identifiziert haben, können wir nun überlegen, wie wir mit den entsprechenden Werten verfahren möchten.\n",
    "\n",
    "Eine sinnvolle Möglichkeit ist es den Datentyp `float64` zu erzwingen und alle nicht interpretierbaren Werte als `NaN` zu kennzeichnen.\n",
    "\n",
    "Dieses Verfahren erlaubt es uns numerische Operationen auf den Spalten durchzuführen. Die NaN-Werte werden dabei einfach ignoriert.\n",
    "\n",
    "Wir verwenden dafür den `pandas`-Befehl `.to_numeric(...)` mit dem Parameter `errors='coerce`, welcher festlegt, wie mit nicht interpretierbaren Werten umgegangen werden soll. \n",
    "\n",
    "Wir beginnen mit der Spalte `P1AK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Erzwingt einen numerischen Datentyp (float64) und b als NaN\n",
    "df_AK['P1AK'] = pd.to_numeric(df_AK['P1AK'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Überprüfung der Datentypen zeigt, dass nun auch die Spalte P1AK den Datentyp `float64` hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AK.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun erzeugt auch die Division keinen Fehler mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_AK['P1AK'].apply(func=prozentuale_belegung)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe (Datentypen 2)\n",
    "\n",
    "Ändere nun auch den Datentyp der übrigen Spalten in `float64`. Dabei kannst du entweder jede Spalte einzelnd ändern oder dir überlegen, wie man alle Spalten gleichzeitig ändern kann. Überprüfe deine Lösung indem du die Datentypen ausgibst (`.dtypes`).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für deine Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Visualisierung\n",
    "\n",
    "Nachdem wir die Daten nun ausreichend vorbereitet haben können wir damit beginnen, die Daten zu visualisieren.\n",
    "\n",
    "Dazu verwenden wir den Befehl `.iplot()`. Dieser ist Teil der `cufflinks`-Bibliothek und erzeugt einen so genannten **Plot** (Graphen) mit Hilfe von `plotly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_AK.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten bereinigen\n",
    "\n",
    "Offensichtlich enthält unser `DataFrame` Daten, die vollkommen **unrealistisch** erscheinen. So liegt die maximale Belegung des Parkplatzes P4.1 bei circa 40.000. \n",
    "\n",
    "Wir müssen uns nun überlegen wie wir mit diesen fehlerhaften Daten umgehen. In der Regel gibt es in einem solchen Fall keine perfekte Lösung.\n",
    "\n",
    "Eine Möglichkeit ist es einen sinnvollen Höchstwert zu ermitteln und alle Werte die darüber liegen \"abzuschneiden\". Dabei müssen wir Folgendes beachten:\n",
    "\n",
    "1. Es gibt keine maximale Belegung, da sich prinzipiell mehr Fahrzeuge auf einem Parkplatz aufhalten können als Parkplätze vorhanden sind. Die Wahl eines Höchstwerts ist daher pragmatisch.\n",
    "2. Wir wissen nicht, ob der Parkplatz zum jeweiligen Zeitpunkt tatsächlich voll war. Ein technischer Fehler könnte auch bei einem leeren Parkplatz zu solchen Werten führen.\n",
    "3. Uns fehlt es an Hintergrundinformationen über die Verteilung der Kapazitäten auf die einzelenen Parkplätze (z.B. bei P4)\n",
    "\n",
    "Unter anderem aus diesen Gründen ersetzen wir die unrealistische Werte stattdessen durch `NaN`.\n",
    "\n",
    "Wir ermitteln zunächst den höchsten Wert, der unser Meinung nach noch als realistisch erscheint. Dazu **sortieren** wir die Werte **absteigend** und entscheiden uns dann von Fall zu Fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setze die Anzahl anzuzeigender Spalten auf 100\n",
    "pd.options.display.max_rows = 100\n",
    "# Sortiere die Werte absteigend\n",
    "df_AK['P41AK'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Wahl eines Schwellenwertes ist nicht eindeutig. Dennoch scheint der Wert **656** noch im realistischem Bereich und liegt gleichzeitg deutlich unter dem nächst höheren Wert von 3072.\n",
    "\n",
    "Wir wählen alle Werte aus, die kleiner oder gleich 656 sind und ersetzen alle anderen durch **NaN**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = df_AK['P41AK'] <= 656\n",
    "df_AK['P41AK'].where(cond=condition, other=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AK['P42AK'].sort_values(ascending=False, na_position='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "    \n",
    "### Aufgabe (Schwellenwert)\n",
    "\n",
    "Verfahre auf die selbe Weise mit den übrigen Spalten. Welche Spalten benötigen einer Überarbeitung? Entscheide dich jeweils für einen sinnvollen Schwellenwert.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier ist Platz für deine Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Überprüfung\n",
    "\n",
    "Zum Schluss überprüfen wir unsere Ergebnisse, indem wir die Daten erneut Plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AK.iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um einen besseren Überblick über die Daten zu bekommen eignet sich die Darstellung in einem so genanntem **Boxplot**. Dort können wir direkt den Median, das Minimum und das Maximum sowie das **q1-Quartil** und das **q3-Quartil** ablesen und erhalten so einen Überblick über die Verteilung der Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_AK.iplot(kind='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für die Auswertung speichern\n",
    "\n",
    "Die vollständig bereinigten Daten speichern wir nun für die spätere Verwendung unter einem neuen Namen ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AK.to_csv('Daten/EinlauefeBereinigt.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 Virtual Environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
